//
// Generated by LLVM NVPTX Back-End
//

.version 6.0
.target sm_30
.address_size 64

	// .globl	softmax_kernel          // -- Begin function softmax_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @softmax_kernel
.visible .entry softmax_kernel(
	.param .u64 softmax_kernel_param_0,
	.param .u64 softmax_kernel_param_1,
	.param .u32 softmax_kernel_param_2,
	.param .u32 softmax_kernel_param_3,
	.param .u32 softmax_kernel_param_4,
	.param .u32 softmax_kernel_param_5
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<143>;
	.reg .f32 	%f<82>;
	.reg .b64 	%rd<18>;

// %bb.0:
	ld.param.u32 	%r19, [softmax_kernel_param_5];
	ld.param.u32 	%r18, [softmax_kernel_param_4];
	ld.param.u64 	%rd2, [softmax_kernel_param_1];
	ld.param.u64 	%rd1, [softmax_kernel_param_0];
	// begin inline asm
	mov.u32 %r142, %ctaid.x;
	// end inline asm
	// begin inline asm
	mov.u32 %r21, %nctaid.x;
	// end inline asm
	ld.param.u32 	%r22, [softmax_kernel_param_2];
	mov.u32 	%r3, %tid.x;
	ld.param.u32 	%r23, [softmax_kernel_param_3];
	and.b32  	%r4, %r3, 31;
	shr.u32 	%r5, %r3, 5;
	and.b32  	%r24, %r3, 1;
	neg.s32 	%r25, %r24;
	and.b32  	%r26, %r25, 4;
	shl.b32 	%r27, %r4, 2;
	and.b32  	%r28, %r27, 8;
	and.b32  	%r29, %r27, 16;
	and.b32  	%r30, %r27, 32;
	and.b32  	%r31, %r27, 64;
	bfe.u32 	%r32, %r3, 5, 1;
	neg.s32 	%r33, %r32;
	and.b32  	%r34, %r33, 128;
	shl.b32 	%r35, %r5, 7;
	and.b32  	%r36, %r35, 256;
	or.b32  	%r37, %r26, %r28;
	or.b32  	%r38, %r37, %r29;
	or.b32  	%r39, %r38, %r30;
	or.b32  	%r40, %r39, %r31;
	or.b32  	%r41, %r40, %r34;
	or.b32  	%r42, %r41, %r36;
	and.b32  	%r43, %r35, 512;
	xor.b32  	%r6, %r42, %r43;
	or.b32  	%r44, %r41, 1024;
	xor.b32  	%r45, %r44, %r36;
	xor.b32  	%r7, %r45, %r43;
	mul.lo.s32 	%r141, %r142, %r23;
	mul.lo.s32 	%r9, %r21, %r23;
	mul.lo.s32 	%r140, %r142, %r22;
	mul.lo.s32 	%r11, %r21, %r22;
	setp.lt.s32 	%p7, %r7, %r19;
	setp.lt.s32 	%p2, %r6, %r19;
	mul.wide.s32 	%rd9, %r6, 4;
	mul.wide.s32 	%rd10, %r7, 4;
	setp.eq.s32 	%p12, %r4, 0;
	mov.u64 	%rd12, global_smem;
	setp.lt.s32 	%p13, %r3, 8;
$L__BB0_1:                              // =>This Inner Loop Header: Depth=1
	setp.ge.s32 	%p1, %r142, %r18;
	@%p1 bra 	$L__BB0_3;
// %bb.2:                               //   in Loop: Header=BB0_1 Depth=1
	mul.wide.s32 	%rd7, %r140, 4;
	add.s64 	%rd8, %rd2, %rd7;
	add.s64 	%rd3, %rd8, %rd9;
	add.s64 	%rd4, %rd8, %rd10;
	mov.b32 	%r51, -8388608;
	// begin inline asm
	mov.u32 %r46, 0x0;
	mov.u32 %r47, 0x0;
	mov.u32 %r48, 0x0;
	mov.u32 %r49, 0x0;
	@%p2 ld.global.v4.b32 { %r46, %r47, %r48, %r49 }, [ %rd3 + 0 ];
	@!%p2 mov.u32 %r46, %r51;
	@!%p2 mov.u32 %r47, %r51;
	@!%p2 mov.u32 %r48, %r51;
	@!%p2 mov.u32 %r49, %r51;
	// end inline asm
	mov.b32 	%f17, %r46;
	mov.b32 	%f18, %r47;
	mov.b32 	%f19, %r48;
	mov.b32 	%f20, %r49;
	// begin inline asm
	mov.u32 %r54, 0x0;
	mov.u32 %r55, 0x0;
	mov.u32 %r56, 0x0;
	mov.u32 %r57, 0x0;
	@%p7 ld.global.v4.b32 { %r54, %r55, %r56, %r57 }, [ %rd4 + 0 ];
	@!%p7 mov.u32 %r54, %r51;
	@!%p7 mov.u32 %r55, %r51;
	@!%p7 mov.u32 %r56, %r51;
	@!%p7 mov.u32 %r57, %r51;
	// end inline asm
	mov.b32 	%f21, %r54;
	mov.b32 	%f22, %r55;
	mov.b32 	%f23, %r56;
	mov.b32 	%f24, %r57;
	bar.sync 	0;
	max.f32 	%f25, %f17, %f18;
	max.f32 	%f26, %f25, %f19;
	max.f32 	%f27, %f26, %f20;
	max.f32 	%f28, %f27, %f21;
	max.f32 	%f29, %f28, %f22;
	max.f32 	%f30, %f29, %f23;
	max.f32 	%f31, %f30, %f24;
	mov.b32 	%r106, %f31;
	shfl.sync.bfly.b32	%r107, %r106, 16, 31, -1;
	mov.b32 	%f32, %r107;
	max.f32 	%f33, %f31, %f32;
	mov.b32 	%r108, %f33;
	shfl.sync.bfly.b32	%r109, %r108, 8, 31, -1;
	mov.b32 	%f34, %r109;
	max.f32 	%f35, %f33, %f34;
	mov.b32 	%r110, %f35;
	shfl.sync.bfly.b32	%r111, %r110, 4, 31, -1;
	mov.b32 	%f36, %r111;
	max.f32 	%f37, %f35, %f36;
	mov.b32 	%r112, %f37;
	shfl.sync.bfly.b32	%r113, %r112, 2, 31, -1;
	mov.b32 	%f38, %r113;
	max.f32 	%f39, %f37, %f38;
	mov.b32 	%r114, %f39;
	shfl.sync.bfly.b32	%r115, %r114, 1, 31, -1;
	mov.b32 	%f40, %r115;
	max.f32 	%f41, %f39, %f40;
	and.b32  	%r116, %r5, 7;
	shl.b32 	%r117, %r116, 2;
	cvt.u64.u32 	%rd11, %r117;
	add.s64 	%rd13, %rd12, %rd11;
	mov.b32 	%r63, %f41;
	cvt.u32.u64 	%r62, %rd13;
	// begin inline asm
	@%p12 st.shared.b32 [ %r62 + 0 ], %r63;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r118, %r3, 2;
	cvt.u64.u32 	%rd14, %r118;
	add.s64 	%rd15, %rd12, %rd14;
	cvt.u32.u64 	%r65, %rd15;
	// begin inline asm
	@%p13 ld.shared.b32 %r64, [ %r65 + 0 ];
	// end inline asm
	mov.b32 	%f42, %r64;
	shfl.sync.bfly.b32	%r119, %r64, 4, 31, -1;
	mov.b32 	%f43, %r119;
	max.f32 	%f44, %f42, %f43;
	mov.b32 	%r120, %f44;
	shfl.sync.bfly.b32	%r121, %r120, 2, 31, -1;
	mov.b32 	%f45, %r121;
	max.f32 	%f46, %f44, %f45;
	mov.b32 	%r122, %f46;
	shfl.sync.bfly.b32	%r123, %r122, 1, 31, -1;
	mov.b32 	%f47, %r123;
	max.f32 	%f48, %f46, %f47;
	and.b32  	%r124, %r4, 7;
	setp.eq.s32 	%p20, %r124, 0;
	and.pred  	%p14, %p13, %p20;
	mov.b32 	%r67, %f48;
	// begin inline asm
	@%p14 st.shared.b32 [ %r65 + 0 ], %r67;
	// end inline asm
	bar.sync 	0;
	ld.shared.f32 	%f49, [global_smem];
	sub.rn.f32 	%f50, %f17, %f49;
	sub.rn.f32 	%f51, %f18, %f49;
	sub.rn.f32 	%f52, %f19, %f49;
	sub.rn.f32 	%f53, %f20, %f49;
	sub.rn.f32 	%f54, %f21, %f49;
	sub.rn.f32 	%f55, %f22, %f49;
	sub.rn.f32 	%f56, %f23, %f49;
	sub.rn.f32 	%f57, %f24, %f49;
	mul.rn.f32 	%f2, %f50, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f1, %f2;
	// end inline asm
	mul.rn.f32 	%f4, %f51, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3, %f4;
	// end inline asm
	mul.rn.f32 	%f6, %f52, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5, %f6;
	// end inline asm
	mul.rn.f32 	%f8, %f53, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f7, %f8;
	// end inline asm
	mul.rn.f32 	%f10, %f54, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f9, %f10;
	// end inline asm
	mul.rn.f32 	%f12, %f55, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f11, %f12;
	// end inline asm
	mul.rn.f32 	%f14, %f56, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f13, %f14;
	// end inline asm
	mul.rn.f32 	%f16, %f57, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f15, %f16;
	// end inline asm
	bar.sync 	0;
	add.rn.f32 	%f58, %f1, %f3;
	add.rn.f32 	%f59, %f58, %f5;
	add.rn.f32 	%f60, %f59, %f7;
	add.rn.f32 	%f61, %f60, %f9;
	add.rn.f32 	%f62, %f61, %f11;
	add.rn.f32 	%f63, %f62, %f13;
	add.rn.f32 	%f64, %f63, %f15;
	mov.b32 	%r125, %f64;
	shfl.sync.bfly.b32	%r126, %r125, 16, 31, -1;
	mov.b32 	%f65, %r126;
	add.rn.f32 	%f66, %f64, %f65;
	mov.b32 	%r127, %f66;
	shfl.sync.bfly.b32	%r128, %r127, 8, 31, -1;
	mov.b32 	%f67, %r128;
	add.rn.f32 	%f68, %f66, %f67;
	mov.b32 	%r129, %f68;
	shfl.sync.bfly.b32	%r130, %r129, 4, 31, -1;
	mov.b32 	%f69, %r130;
	add.rn.f32 	%f70, %f68, %f69;
	mov.b32 	%r131, %f70;
	shfl.sync.bfly.b32	%r132, %r131, 2, 31, -1;
	mov.b32 	%f71, %r132;
	add.rn.f32 	%f72, %f70, %f71;
	mov.b32 	%r133, %f72;
	shfl.sync.bfly.b32	%r134, %r133, 1, 31, -1;
	mov.b32 	%f73, %r134;
	add.rn.f32 	%f74, %f72, %f73;
	mov.b32 	%r69, %f74;
	// begin inline asm
	@%p12 st.shared.b32 [ %r62 + 0 ], %r69;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p13 ld.shared.b32 %r70, [ %r65 + 0 ];
	// end inline asm
	mov.b32 	%f75, %r70;
	shfl.sync.bfly.b32	%r135, %r70, 4, 31, -1;
	mov.b32 	%f76, %r135;
	add.rn.f32 	%f77, %f75, %f76;
	mov.b32 	%r136, %f77;
	shfl.sync.bfly.b32	%r137, %r136, 2, 31, -1;
	mov.b32 	%f78, %r137;
	add.rn.f32 	%f79, %f77, %f78;
	mov.b32 	%r138, %f79;
	shfl.sync.bfly.b32	%r139, %r138, 1, 31, -1;
	mov.b32 	%f80, %r139;
	add.rn.f32 	%f81, %f79, %f80;
	mov.b32 	%r73, %f81;
	// begin inline asm
	@%p14 st.shared.b32 [ %r65 + 0 ], %r73;
	// end inline asm
	bar.sync 	0;
	mov.b32 	%r75, %f1;
	ld.shared.u32 	%r76, [global_smem];
	// begin inline asm
	div.full.f32 %r98, %r75, %r76;
	// end inline asm
	mov.b32 	%r78, %f3;
	// begin inline asm
	div.full.f32 %r99, %r78, %r76;
	// end inline asm
	mov.b32 	%r81, %f5;
	// begin inline asm
	div.full.f32 %r100, %r81, %r76;
	// end inline asm
	mov.b32 	%r84, %f7;
	// begin inline asm
	div.full.f32 %r101, %r84, %r76;
	// end inline asm
	mov.b32 	%r87, %f9;
	// begin inline asm
	div.full.f32 %r102, %r87, %r76;
	// end inline asm
	mov.b32 	%r90, %f11;
	// begin inline asm
	div.full.f32 %r103, %r90, %r76;
	// end inline asm
	mov.b32 	%r93, %f13;
	// begin inline asm
	div.full.f32 %r104, %r93, %r76;
	// end inline asm
	mov.b32 	%r96, %f15;
	// begin inline asm
	div.full.f32 %r105, %r96, %r76;
	// end inline asm
	mul.wide.s32 	%rd16, %r141, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s64 	%rd5, %rd17, %rd9;
	add.s64 	%rd6, %rd17, %rd10;
	// begin inline asm
	@%p2 st.global.v4.b32 [ %rd5 + 0 ], { %r98, %r99, %r100, %r101 };
	// end inline asm
	// begin inline asm
	@%p7 st.global.v4.b32 [ %rd6 + 0 ], { %r102, %r103, %r104, %r105 };
	// end inline asm
	add.s32 	%r142, %r142, %r21;
	add.s32 	%r141, %r141, %r9;
	add.s32 	%r140, %r140, %r11;
	bra.uni 	$L__BB0_1;
$L__BB0_3:
	ret;
                                        // -- End function
}
